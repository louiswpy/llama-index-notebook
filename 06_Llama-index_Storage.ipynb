{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1472cb-ab1f-48fc-b8d2-e369baee4557",
   "metadata": {},
   "source": [
    "## Setting LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d45b36d-757f-4acd-8083-995138095f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b5c8e0-4619-40e1-9141-f3196290ff92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "#print(\"Open AI - \",os.getenv(\"LITELLM_URL\"),os.getenv(\"OPENAI_API_MODEL\"), os.getenv(\"OPENAI_API_EMBEDDING\"))\n",
    "#print(\"OLLAMA  - \",os.getenv(\"OLLAMA_URL\"),os.getenv(\"OLLAMA_MODEL\"))\n",
    "#print(\"Local OLLAMA - \",os.getenv(\"OLLAMA_LOCAL_URL\"),os.getenv(\"OLLAMA_LOCAL_MODEL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c5c71d-7466-40e9-a6d9-e62837f621ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8a433aa-4f89-4e06-8acd-780e730536bd",
   "metadata": {},
   "source": [
    "### RUN LLM AS OLLAMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4008df15-e79d-4fb2-8269-08182ae74b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install OPEN AI LLM, skip if already installed\n",
    "!pipenv install llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88433662-bed6-4bdf-8991-f02f730792b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "The capital of France is **Paris**. ðŸ‡«ðŸ‡·  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "api_base=os.getenv(\"OLLAMA_LOCAL_URL\")\n",
    "model=os.getenv(\"OLLAMA_LOCAL_MODEL\")\n",
    "Settings.llm = Ollama(model=model, base_url=api_base,request_timeout=360.0)\n",
    "\n",
    "# use remote ollam\n",
    "\"\"\"\n",
    "api_base=os.getenv(\"OLLAMA_URL\")\n",
    "model=os.getenv(\"OLLAMA_MODEL\")\n",
    "llm = Ollama(model=model, base_url=api_base,request_timeout=360.0)\n",
    "\"\"\"\n",
    "#test run\n",
    "response = Settings.llm.complete(\"What is the capital of France?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34bf597-435b-464d-afc4-49f852d60479",
   "metadata": {},
   "source": [
    "### RUN LLM AS OPEN AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10f8e1-1bef-44e4-bb0d-671a5a7ac66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install OPEN AI LLM, skip if already installed\n",
    "!pipenv install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca4af2b-3cbf-42b5-8a0c-eccb3e796188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "api_base=os.getenv(\"LITELLM_URL\")\n",
    "model=os.getenv(\"OPENAI_API_MODEL\")\n",
    "\n",
    "Settings.llm = OpenAI(\n",
    "    model=model,\n",
    "    api_base = api_base,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# resp = Settings.llm.complete(\"What is the capital of France?\")\n",
    "# print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f57c66-5521-4e24-9197-07ce916f7491",
   "metadata": {},
   "source": [
    "## Setting Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1d1b49-087e-49e3-906b-da53d09fd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use open AI embedding\n",
    "# can skip if use local embedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "api_base=os.getenv(\"LITELLM_URL\")\n",
    "embedding_model=os.getenv(\"OPENAI_API_EMBEDDING\")\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model_name=embedding_model,\n",
    "    api_base = api_base,\n",
    ")\n",
    "# embed_text = Settings.embed_model.get_text_embedding(\"hello\")\n",
    "# print(f\"{len(embed_text)}, {embed_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e1a5b2d-b956-4d98-abf3-be4d88bce361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f809f11-dec8-4a34-8ca5-e18777f56a50",
   "metadata": {},
   "source": [
    "### Load and Parse document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0ceced-ddc8-4648-be44-c594967664e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleKeywordTableIndex\n",
    "from llama_index.core import SummaryIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed08805f-6e69-4952-b701-59cdf35ddf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader,Document\n",
    "documents = SimpleDirectoryReader(\"./data/paul\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f6d1c6c-c325-4f98-b248-f71bce440da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "nodes = SentenceSplitter().get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081098b-7064-4240-a806-36fdd82d2b07",
   "metadata": {},
   "source": [
    "## Store using simple store in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03ce247f-4c6b-4e11-af65-2fabd128241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb59e50-3b3a-4d1d-9ab2-247a61af2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d1f7935-7441-4587-9a7f-41f2df991abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(docstore=docstore)\n",
    "summary_index = SummaryIndex(nodes, storage_context=storage_context)\n",
    "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "keyword_table_index = SimpleKeywordTableIndex(\n",
    "    nodes, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222e3d6-7113-4977-b1fe-a8f207e2ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = summary_index.as_query_engine()\n",
    "response = query_engine.query(\"What is a summary of this document?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "526fd38f-dc28-4279-b48a-5664321f1747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing up, the author focused on writing and programming outside of school. Initially, they wrote short stories, which they later described as lacking plot and depth. They began programming on an IBM 1401 in 9th grade, where they encountered challenges due to the limitations of the technology, such as using punch cards for input. Eventually, they transitioned to microcomputers, starting with a TRS-80, where they wrote simple games and a word processor. Despite their interest in programming, they initially planned to study philosophy in college but later switched to artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "query_engine = vector_index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261375f-c824-4b7c-aa7e-3c8314475c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = keyword_table_index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do after his time at YC?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46710c7-9f81-4922-a777-3f9893e8279d",
   "metadata": {},
   "source": [
    "### Store using Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba278fb3-1cba-4c2c-939e-88f17508a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pipenv install llama-index-storage-docstore-mongodb llama-index-storage-index-store-mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9172ad1d-5077-4b1a-92f6-7aa535643e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mongodb://localhost:27017/\n"
     ]
    }
   ],
   "source": [
    "MONGO_URI = os.environ[\"MONGO_URI\"]\n",
    "print(MONGO_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7d3ad2b-8ac3-44d9-aa93-88472c98d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.index_store.mongodb import MongoIndexStore\n",
    "from llama_index.core import VectorStoreIndex,StorageContext\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "# create (or load) index store\n",
    "index_store = MongoIndexStore.from_uri(uri=MONGO_URI)\n",
    "\n",
    "# create storage context\n",
    "storage_context = StorageContext.from_defaults(index_store=index_store)\n",
    "\n",
    "# build index\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "vector_id = index.index_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0061eef8-8e50-4b09-8045-90b9bcafe6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = load_index_from_storage(\n",
    "    storage_context=storage_context, index_id=vector_id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ea375f4-38ce-4d1d-85d7-5224785ef078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing up, the author focused on writing and programming outside of school. Initially, they wrote short stories, which they later described as lacking in plot but filled with characters expressing strong feelings. Their early programming experiences began with the IBM 1401, where they learned to write programs using punch cards, although they found it puzzling and limited. Later, they became more engaged with programming when they got a TRS-80 microcomputer, which allowed them to write simple games and other programs. Despite enjoying programming, the author initially planned to study philosophy in college, believing it to be a more profound field.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "result = query_engine.query(\"What did the author do growing up?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dac89118-8c18-42d6-baf9-948bae587688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.docstore.mongodb import MongoDocumentStore\n",
    "from llama_index.storage.index_store.mongodb import MongoIndexStore\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=MongoDocumentStore.from_uri(uri=MONGO_URI),\n",
    "    index_store=MongoIndexStore.from_uri(uri=MONGO_URI),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "923dbc9c-67c5-4054-8b5f-43eb1409a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context.docstore.add_documents(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88882517-02ed-4704-8451-a6dc5dd6db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_index = SummaryIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f31cdd3-e2a5-4e42-a03d-6a090d6e50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87535ccf-9269-4f67-80e7-0bbb6928bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_table_index = SimpleKeywordTableIndex(\n",
    "    nodes, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c66bc51f-7987-4f7e-893b-ea65e6c43d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing up, the author focused on writing and programming outside of school. Initially, they wrote short stories, which they later described as lacking plot and depth. They began programming on an IBM 1401 in 9th grade, using punch cards to input data, but found it puzzling and limited. Eventually, they got a TRS-80 microcomputer, which allowed them to start programming more effectively, creating simple games and a word processor. Despite enjoying programming, the author initially planned to study philosophy in college but later switched to artificial intelligence after finding philosophy courses unengaging.\n"
     ]
    }
   ],
   "source": [
    "query_engine = vector_index.as_query_engine()\n",
    "vector_response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(vector_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66915928-0fb9-4f08-a0bb-76d0e7c80f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24f9e916-a051-405e-8501-a5c4fdd1d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = summary_index.index_id\n",
    "vector_id = vector_index.index_id\n",
    "keyword_id = keyword_table_index.index_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "453af60e-41a5-4305-8b78-336e8eba1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load from storage\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "# re-create storage context\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=MongoDocumentStore.from_uri(uri=MONGO_URI),\n",
    "    index_store=MongoIndexStore.from_uri(uri=MONGO_URI),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ba21fdf-8605-4c76-b3fe-fd94e2b79066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load indices\n",
    "summary_index = load_index_from_storage(\n",
    "    storage_context=storage_context, index_id=list_id\n",
    ")\n",
    "vector_index = load_index_from_storage(\n",
    "    storage_context=storage_context, index_id=vector_id\n",
    ")\n",
    "keyword_table_index = load_index_from_storage(\n",
    "    storage_context=storage_context, index_id=keyword_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3599ec15-a582-4c85-9274-dae0d6da3309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Response\n"
     ]
    }
   ],
   "source": [
    "query_engine = vector_index.as_query_engine(llm=Settings.llm)\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518c002-f7df-4407-bec6-be99eec3daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = keyword_table_index.as_query_engine()\n",
    "keyword_response = query_engine.query(\n",
    "    \"What did the author do after his time at YC?\"\n",
    ")\n",
    "print(keyword_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb4dfc-b6d6-4667-af10-a81c077bec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = summary_index.as_query_engine()\n",
    "list_response = query_engine.query(\"What is a summary of this document?\")\n",
    "print(list_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41423623-3973-4333-b210-90bb7007b7a3",
   "metadata": {},
   "source": [
    "### Postgres Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85cd803-7d1d-4686-8990-d1ec43fc648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index-vector-stores-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "82abc678-7dec-4087-8608-62461d983e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "import textwrap\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "42a63e94-b55a-4513-8988-3fd20a49cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import make_url\n",
    "\n",
    "url = make_url(connection_string)\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=\"paul_graham_essay\",\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    "    hnsw_kwargs={\n",
    "        \"hnsw_m\": 16,\n",
    "        \"hnsw_ef_construction\": 64,\n",
    "        \"hnsw_ef_search\": 40,\n",
    "        \"hnsw_dist_method\": \"vector_cosine_ops\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0a249-35ec-418a-82fc-c58d2f8636a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, show_progress=True\n",
    ")\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46448d67-9c82-4efa-8c87-d8711349b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "connection_string = \"postgresql://postgres:password@localhost:5432\"\n",
    "db_name = \"vector_db\"\n",
    "conn = psycopg2.connect(connection_string)\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn.cursor() as c:\n",
    "    c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "    c.execute(f\"CREATE DATABASE {db_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc100a-d529-4929-a6f2-45fe10b9a2d0",
   "metadata": {},
   "source": [
    "### Chroma Vector  DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df688e-224a-4828-90a1-8c269a45db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pipenv install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b92d476-4a5f-4ae5-8fd5-213f71d5ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9968135b-e038-44b6-9e60-471803480df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "chroma_collection = chroma_client.create_collection(\"paul\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3009d066-9e2f-400c-ae29-6400a0e9e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5dbe4-ba9f-4737-b434-076b5ea661a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc2736-9b53-4c43-aae8-d2d67a2d3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do after his time at YC?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-2",
   "language": "python",
   "name": "llama-index-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
