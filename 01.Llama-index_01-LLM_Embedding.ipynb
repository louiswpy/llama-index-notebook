{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1472cb-ab1f-48fc-b8d2-e369baee4557",
   "metadata": {},
   "source": [
    "## Setting LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d45b36d-757f-4acd-8083-995138095f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0b5c8e0-4619-40e1-9141-f3196290ff92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "#print(\"Open AI - \",os.getenv(\"LITELLM_URL\"),os.getenv(\"OPENAI_API_MODEL\"), os.getenv(\"OPENAI_API_EMBEDDING\"))\n",
    "#print(\"OLLAMA  - \",os.getenv(\"OLLAMA_URL\"),os.getenv(\"OLLAMA_MODEL\"))\n",
    "#print(\"Local OLLAMA - \",os.getenv(\"OLLAMA_LOCAL_URL\"),os.getenv(\"OLLAMA_LOCAL_MODEL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c5c71d-7466-40e9-a6d9-e62837f621ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8a433aa-4f89-4e06-8acd-780e730536bd",
   "metadata": {},
   "source": [
    "### RUN LLM AS OLLAMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79360ad-c483-45c2-9fa9-877ce269a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install OPEN AI LLM, skip if already installed\n",
    "!pipenv install llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88433662-bed6-4bdf-8991-f02f730792b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**. ðŸ‡«ðŸ‡·  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "api_base=os.getenv(\"OLLAMA_LOCAL_URL\")\n",
    "model=os.getenv(\"OLLAMA_LOCAL_MODEL\")\n",
    "llm = Ollama(model=model, base_url=api_base,request_timeout=120.0)\n",
    "\n",
    "# use remote ollam\n",
    "\"\"\"\n",
    "api_base=os.getenv(\"OLLAMA_URL\")\n",
    "model=os.getenv(\"OLLAMA_MODEL\")\n",
    "llm = Ollama(model=model, base_url=api_base,request_timeout=180.0)\n",
    "\"\"\"\n",
    "#test run\n",
    "response = llm.complete(\"What is the capital of France?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34bf597-435b-464d-afc4-49f852d60479",
   "metadata": {},
   "source": [
    "### RUN LLM AS OPEN AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244e17d-0b63-47b5-a1d4-6826dd9fe54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install OPEN AI LLM, skip if already installed\n",
    "!pipenv install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34211605-5eb2-4aa7-aa9b-12ca23c0babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "api_base=os.getenv(\"LITELLM_URL\")\n",
    "model=os.getenv(\"OPENAI_API_MODEL\")\n",
    "\n",
    "Settings.llm = OpenAI(\n",
    "    model=model,\n",
    "    api_base = api_base,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "resp = Settings.llm.complete(\"What is the capital of France?\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65900a80-98ba-4a73-92ef-826cf82d8aa6",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Tokenization is the process of breaking text into smaller units (tokens) that LLMs can process, converting them into numerical IDs for model input. It ensures efficient and consistent text representation, enabling the model to handle fixed-length sequences and unseen words using techniques like subword or byte pair encoding (BPE). Tokenization occurs before text embedding, generation, or any LLM processing to prepare data for computation.\n",
    "\n",
    "- Llama-index default using tiktoken as use by Open AI\n",
    "- Non Open AI model can use trasformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38236a5f-b721-431d-ad54-09f1aa3da963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9906, 4435, 0]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "#for Open AI\n",
    "tokenizer1 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\n",
    "print(tokenizer1(\"Hello World!\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4de2871-1bed-421b-9c90-53c0077f6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install OPEN AI LLM, skip if already installed\n",
    "!pipenv install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8d16ff-bf86-4bda-b82c-9e21e9a42e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\.virtualenvs\\llamaIndex_agent-J6ScUDy8\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 22557, 3304, 28808], 'attention_mask': [1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# huggingface\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-beta\")\n",
    "print(tokenizer2(\"Hello World!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7c7d4c-9986-4473-b1a3-acf4b277b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.tokenizer = tokenizer1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f57c66-5521-4e24-9197-07ce916f7491",
   "metadata": {},
   "source": [
    "## Setting Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f1d1b49-087e-49e3-906b-da53d09fd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use open AI embedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "api_base=os.getenv(\"LITELLM_URL\")\n",
    "embedding_model=os.getenv(\"OPENAI_API_EMBEDDING\")\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model_name=embedding_model,\n",
    "    api_base = api_base,\n",
    ")\n",
    "# embed_text = Settings.embed_model.get_text_embedding(\"hello\")\n",
    "# print(f\"{len(embed_text)}, {embed_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905ce11-5f56-40fd-b0c1-845f30ddc697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model from Hugging face into local  (unable to run in notebook)\n",
    "!pipenv install llama-index-embeddings-huggingface\n",
    "!pipenv install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781ad46b-7ac4-44f6-92bc-0c1e792410d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384, [-0.0643514096736908, -0.06281544268131256, 0.05967331677675247, -0.062457676976919174, -0.013114610686898232, 0.018242744728922844, 0.06856439262628555, 0.03575027361512184, 0.04076302796602249, 0.005130363628268242, 0.008038632571697235, -0.07947416603565216, 0.025934062898159027, 0.049173787236213684, 0.0275560449808836, -0.0004877340397797525, 0.04075757414102554, -0.051806751638650894, -0.11306574940681458, 0.004447642248123884, 0.009401279501616955, 0.02884845621883869, -0.05381949245929718, -0.04361865669488907, 0.0051504215225577354, -0.0023293327540159225, 0.02580035664141178, -0.010388363152742386, -0.008328532800078392, -0.023409048095345497, -0.03143850341439247, 0.004619847983121872, 0.04228010028600693, 0.024808714166283607, 0.018703529611229897, -0.026772426441311836, 0.038852423429489136, -0.013954431749880314, -0.07236617058515549, -0.0033572171814739704, 0.05542605742812157, -0.051612697541713715, 0.0002378230419708416, -0.022276420146226883, 0.03365354984998703, -0.037540875375270844, 0.027857288718223572, 0.06835237890481949, 0.0548696406185627, -0.016399666666984558, -0.057094261050224304, 0.007857553660869598, -0.016096236184239388, 0.004937533754855394, 0.009864291176199913, 0.10300898551940918, 0.097894087433815, -0.044865455478429794, 0.03518504649400711, 0.015558396466076374, 0.035410162061452866, -0.003449141513556242, -0.15528585016727448, 0.08291762322187424, -0.005542411468923092, -0.001236134790815413, 0.00045609258813783526, -0.022184591740369797, 0.038255661725997925, 0.011689797043800354, 0.03093821182847023, -0.020977571606636047, -0.013455699197947979, 0.04620688408613205, 0.003680831752717495, 0.0001770320814102888, 0.04157368466258049, -0.023622993379831314, 0.04193776473402977, -0.07004522532224655, -0.011848147958517075, -0.006516104564070702, -0.011711101047694683, 0.015360464341938496, -0.020714228972792625, -0.03354179859161377, -0.015045996755361557, 0.07541265338659286, -0.01744241826236248, -0.0063411458395421505, -0.025643279775977135, -0.005480662453919649, 0.0023337400052696466, 0.024016832932829857, -0.04606729373335838, -0.028315924108028412, -0.0037799824494868517, 0.016830872744321823, -0.06882524490356445, 0.27498897910118103, -0.050759125500917435, 0.009099953807890415, 0.061807699501514435, -0.060746558010578156, 0.007060582749545574, 0.03667232021689415, 0.02086249366402626, -0.01754191145300865, -0.014581294730305672, -0.0036316567566245794, 0.020078958943486214, -0.05721038207411766, 0.014743697829544544, -0.00573606276884675, 0.0048774429596960545, -0.027101339772343636, 0.021693330258131027, 0.012375851161777973, 0.09531567245721817, -0.07314718514680862, 0.00405063945800066, 0.01586240343749523, -0.06503868103027344, -0.0030829200986772776, 0.07738525420427322, -0.058763641864061356, 0.039486996829509735, 0.10314624011516571, -0.01464857067912817, 0.043701376765966415, 0.029425814747810364, 0.05574662610888481, -0.0775332897901535, -0.04405191168189049, -0.036656517535448074, 0.0018454799428582191, -0.018694646656513214, -0.02750006876885891, -0.03069002740085125, -0.05940474569797516, -0.02997993677854538, -0.09800258278846741, -0.031593356281518936, -0.12274046242237091, -0.0013519988860934973, -0.016002049669623375, -0.0287519209086895, 0.02188321016728878, -0.027753453701734543, -0.027522124350070953, -0.0294098611921072, 0.029470425099134445, -0.013537844642996788, -0.04563586041331291, 0.014369062148034573, -0.025050239637494087, 0.024149633944034576, 0.03738291561603546, 0.00893163587898016, 0.04788382723927498, 0.013521270826458931, -0.044579632580280304, -0.01230187714099884, -0.007100851275026798, -0.07566025853157043, -0.14803683757781982, 0.008700805716216564, 0.01791548915207386, 0.03565490245819092, 0.027064893394708633, 0.048640575259923935, 0.022801900282502174, -0.030175570398569107, 0.06705434620380402, 0.0788547471165657, 0.02682318724691868, 0.03315233066678047, 0.017384780570864677, -0.01715104468166828, -0.009304078295826912, 0.02303340658545494, -0.035746436566114426, -0.01633935607969761, -0.004886934068053961, 0.012249795719981194, -0.006080283783376217, 0.01774435117840767, 0.035347696393728256, -0.00010801790631376207, 0.03674543648958206, 0.017773352563381195, 0.04381722956895828, 0.023670056834816933, 0.014517082832753658, -0.052691519260406494, 0.016052594408392906, 0.06266935914754868, -0.03459605574607849, 0.009809095412492752, -0.016126733273267746, 0.05901280418038368, 0.014289284124970436, 0.032948367297649384, 0.061182599514722824, 0.07811295241117477, -0.01626473106443882, 0.011941572651267052, -0.006419934798032045, 0.05746534466743469, 0.010521266609430313, -0.022746475413441658, -0.027100451290607452, 0.09178747236728668, -0.01586565002799034, -0.005516413599252701, -0.06237070634961128, -0.016929611563682556, 0.040381137281656265, -0.0075584761798381805, 0.04591486603021622, -0.0015817086677998304, -0.028985287994146347, -0.0913950726389885, -0.25929519534111023, 0.09825991094112396, 0.0028083366341888905, -0.04301437363028526, 0.05901903659105301, -0.008071297779679298, 0.05556103587150574, -0.03306474909186363, 0.10811469703912735, 0.007726059295237064, 0.015010528266429901, -0.04567156732082367, -0.024807879701256752, 0.012847664766013622, 0.017059670761227608, 0.03477490693330765, -0.007689714897423983, -0.044771838933229446, 0.035266149789094925, -0.044575925916433334, 0.01806163601577282, 0.005593900568783283, 0.03434033319354057, -0.03645038604736328, 0.0010545513359829783, -0.055361565202474594, 0.15728548169136047, 0.14839471876621246, 0.03490885719656944, -0.00236348039470613, 0.04965810850262642, -0.04705646261572838, -0.01848248951137066, -0.17373105883598328, 0.03313353285193443, 0.054919999092817307, 0.00377354072406888, -0.0653173103928566, -0.06316477805376053, -0.028408175334334373, -0.03801541402935982, -0.03417038917541504, 0.015478026121854782, -0.04500178247690201, -0.01599196158349514, -0.08225301653146744, -0.06663429737091064, -0.0009536471334286034, -0.07696252316236496, 0.028513893485069275, 0.037064358592033386, -0.019745783880352974, 0.0407986044883728, 0.04250616580247879, -0.026886368170380592, -0.059440355747938156, -0.002017297549173236, -0.028444087132811546, -0.027319222688674927, 0.02152448147535324, -0.010974463075399399, 0.026448911055922508, -0.013895882293581963, 0.0017122504068538547, -0.04092208296060562, 0.09001154452562332, -0.029658887535333633, -0.03533152490854263, 0.03928504139184952, -0.008429658599197865, -0.005777115933597088, -0.03054118901491165, 0.0054266974329948425, 0.0024747175630182028, 0.031535521149635315, 0.0569167323410511, -0.005268177483230829, 0.006107420660555363, -0.037406038492918015, -0.0658351331949234, 0.014817222021520138, -0.0012354686623439193, 0.05820922926068306, 0.007600602228194475, 0.018782267346978188, 0.0558372363448143, 0.06525985151529312, -0.03285060077905655, 0.029670104384422302, -0.06294279545545578, -0.039434079080820084, 0.0038942787796258926, 0.013626757077872753, -0.12317077815532684, 0.03034242056310177, -0.03490760177373886, -0.27943864464759827, 0.07225740700960159, -0.02208711765706539, 0.022965770214796066, -0.057294003665447235, 0.06515367329120636, 0.015204430557787418, 0.06725762039422989, -0.08060136437416077, 0.028286803513765335, -0.018920307978987694, 0.06957133859395981, 0.021487509831786156, 0.04280709847807884, -0.03261195123195648, 0.05981247499585152, 0.049415528774261475, -0.060154955834150314, 0.001731449505314231, -0.01945170760154724, -0.02381839230656624, 0.0011113551445305347, 0.18774321675300598, -0.06392984837293625, 0.08531282842159271, 0.025005491450428963, -0.017223035916686058, 0.04093329608440399, 0.014099824242293835, -0.020683875307440758, -0.006493948865681887, 0.01013084128499031, 0.03254575654864311, -0.03782932832837105, 0.040052372962236404, 0.010649631731212139, -0.03729245439171791, 0.00734131783246994, 0.011504464782774448, -0.017407609149813652, -0.04199723154306412, 0.0067356303334236145, -0.0474507175385952, 0.045427143573760986, 0.08387486636638641, -0.050005488097667694, -0.016262300312519073, 0.006276160944253206, -0.0332261361181736, -0.012378769926726818, 0.004985004663467407, 0.042951613664627075, 0.015101579017937183, 0.059542179107666016, 0.009874065406620502, -0.00029309719684533775, -0.004914447199553251, -0.011296135373413563, -0.0016675028018653393, -0.026640063151717186, -0.029398582875728607, -0.032623108476400375, 0.0393374003469944, 0.04107529670000076, -0.009852482937276363]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "embed_text = Settings.embed_model.get_text_embedding(\"hello\")\n",
    "print(f\"{len(embed_text)}, {embed_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6326ee-8615-472c-9fc9-0f6f899c6d52",
   "metadata": {},
   "source": [
    "### HuggingFace Optimum ONNX Embeddings (unable to run in notebook)\n",
    "ONNX embeddings are vector representations generated by models saved in the ONNX format, which allows for cross-framework compatibility and efficient deployment across various hardware platforms. These embeddings are used in NLP tasks like semantic search or document classification. The ONNX format optimizes performance, allowing faster inference and reduced resource usage compared to other formats like PyTorch or TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2367802-f413-4a94-a9a3-4d2f1ad83e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pipenv install transformers optimum[exporters]\n",
    "!pipenv install llama-index-embeddings-huggingface-optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fdf1f46-3c7a-4693-ab6b-b2cfbe7296f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved optimum model to ./bge_onnx. Use it with `embed_model = OptimumEmbedding(folder_name='./bge_onnx')`.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface_optimum import OptimumEmbedding\n",
    "\n",
    "OptimumEmbedding.create_and_save_optimum_model(\n",
    "    \"BAAI/bge-small-en-v1.5\", \"./bge_onnx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a5e137-5931-476e-84f9-73ef906fa5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = OptimumEmbedding(folder_name=\"./bge_onnx\")\n",
    "embed_text = Settings.embed_model.get_text_embedding(\"hello\")\n",
    "print(f\"{len(embed_text)}, {embed_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0bff1-afdb-412e-b679-ab31f0341f89",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed08805f-6e69-4952-b701-59cdf35ddf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader(\"./data/paul\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63f61de0-b210-4fc8-aaf9-a8ba55910257",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb513010-1692-45e3-90cf-b7fd939c38c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a writer and programmer known for his essays on technology, startups, and entrepreneurship. He co-founded Y Combinator, a startup accelerator, and has been influential in the tech startup community. His experiences and reflections on running Y Combinator and writing essays are discussed in his work.\n"
     ]
    }
   ],
   "source": [
    "query = index.as_query_engine(llm=Settings.llm)\n",
    "print(query.query(\"Who is Paul Graha?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dec4c564-d057-4485-bd22-5938d4614524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "text_qa_template_str = (\n",
    "    \"Context information is\"\n",
    "    \" below.\\n---------------------\\n{context_str}\\n---------------------\\nUsing\"\n",
    "    \" both the context information and also using your own knowledge, answer\"\n",
    "    \" the question: {query_str}\\nIf the context isn't helpful, you can also\"\n",
    "    \" answer the question on your own.\\n\"\n",
    ")\n",
    "text_qa_template = PromptTemplate(text_qa_template_str)\n",
    "\n",
    "refine_template_str = (\n",
    "    \"The original question is as follows: {query_str}\\nWe have provided an\"\n",
    "    \" existing answer: {existing_answer}\\nWe have the opportunity to refine\"\n",
    "    \" the existing answer (only if needed) with some more context\"\n",
    "    \" below.\\n------------\\n{context_msg}\\n------------\\nUsing both the new\"\n",
    "    \" context and your own knowledge, update or repeat the existing answer.\\n\"\n",
    ")\n",
    "refine_template = PromptTemplate(refine_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "603eb256-dd61-430a-aa96-7466166e338d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>} template_vars=['context_str', 'query_str'] kwargs={} output_parser=None template_var_mappings=None function_mappings=None template=\"Context information is below.\\n---------------------\\n{context_str}\\n---------------------\\nUsing both the context information and also using your own knowledge, answer the question: {query_str}\\nIf the context isn't helpful, you can also answer the question on your own.\\n\"\n"
     ]
    }
   ],
   "source": [
    "print(text_qa_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7218f4f-3096-49c7-81d3-fc22b58e1885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Biden is an American politician and attorney who has served as the 46th President of the United States since January 20, 2021. He was born on November 20, 1942, in Scranton, Pennsylvania. Before his presidency, Biden had a long career in politics, including serving as a U.S. Senator from Delaware from 1973 to 2009. He was also the Vice President of the United States under President Barack Obama from 2009 to 2017.\n",
      "\n",
      "Biden is a member of the Democratic Party and has focused on issues such as healthcare, foreign policy, and climate change during his political career. His presidency has been marked by efforts to address the COVID-19 pandemic, economic recovery, and social justice issues.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    index.as_query_engine(\n",
    "        text_qa_template=text_qa_template,\n",
    "        refine_template=refine_template,\n",
    "        llm=Settings.llm,\n",
    "    ).query(\"Who is Joe Biden?\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaIndex",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
