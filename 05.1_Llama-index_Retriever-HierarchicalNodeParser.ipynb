{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1472cb-ab1f-48fc-b8d2-e369baee4557",
   "metadata": {},
   "source": [
    "## Setting LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d45b36d-757f-4acd-8083-995138095f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72f3b23-f340-4408-a4da-e9bee96e76a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "#print(\"Open AI - \",os.getenv(\"LITELLM_URL\"),os.getenv(\"OPENAI_API_MODEL\"), os.getenv(\"OPENAI_API_EMBEDDING\"))\n",
    "#print(\"OLLAMA  - \",os.getenv(\"OLLAMA_URL\"),os.getenv(\"OLLAMA_MODEL\"))\n",
    "#print(\"Local OLLAMA - \",os.getenv(\"OLLAMA_LOCAL_URL\"),os.getenv(\"OLLAMA_LOCAL_MODEL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c5c71d-7466-40e9-a6d9-e62837f621ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8a433aa-4f89-4e06-8acd-780e730536bd",
   "metadata": {},
   "source": [
    "### RUN LLM AS OLLAMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96176b21-78d2-4446-8e21-3398e1a33730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install OPEN AI LLM, skip if already installed\n",
    "!pipenv install llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88433662-bed6-4bdf-8991-f02f730792b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\napi_base=os.getenv(\"OLLAMA_URL\")\\nmodel=os.getenv(\"OLLAMA_MODEL\")\\nllm = Ollama(model=model, base_url=api_base,request_timeout=180.0)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "api_base=os.getenv(\"OLLAMA_LOCAL_URL\")\n",
    "model=os.getenv(\"OLLAMA_LOCAL_MODEL\")\n",
    "llm = Ollama(model=model, base_url=api_base,request_timeout=120.0)\n",
    "\n",
    "# use remote ollam\n",
    "\"\"\"\n",
    "api_base=os.getenv(\"OLLAMA_URL\")\n",
    "model=os.getenv(\"OLLAMA_MODEL\")\n",
    "llm = Ollama(model=model, base_url=api_base,request_timeout=180.0)\n",
    "\"\"\"\n",
    "#test run\n",
    "#response = llm.complete(\"What is the capital of France?\")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34bf597-435b-464d-afc4-49f852d60479",
   "metadata": {},
   "source": [
    "### RUN LLM AS OPEN AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca19e9e-777e-4102-a4d2-95327a8275e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install OPEN AI LLM, skip if already installed\n",
    "!pipenv install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab0492e1-cfed-44e3-9e6e-4852a1920290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "api_base=os.getenv(\"LITELLM_URL\")\n",
    "model=os.getenv(\"OPENAI_API_MODEL\")\n",
    "\n",
    "Settings.llm = OpenAI(\n",
    "    model=model,\n",
    "    api_base = api_base,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "#resp = Settings.llm.complete(\"What is the capital of France?\")\n",
    "#print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f57c66-5521-4e24-9197-07ce916f7491",
   "metadata": {},
   "source": [
    "## Setting Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1d1b49-087e-49e3-906b-da53d09fd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use open AI embedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "api_base=os.getenv(\"LITELLM_URL\")\n",
    "embedding_model=os.getenv(\"OPENAI_API_EMBEDDING\")\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model_name=embedding_model,\n",
    "    api_base = api_base,\n",
    ")\n",
    "#embed_text = Settings.embed_model.get_text_embedding(\"hello\")\n",
    "#print(f\"{len(embed_text)}, {embed_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed08805f-6e69-4952-b701-59cdf35ddf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader(\"./data/paul\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd28b56-ba06-4c70-a66c-67908a4ece59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edca53b-581c-4093-80e0-4a9d33add125",
   "metadata": {},
   "source": [
    "### Node\n",
    "Nodes represent \"chunks\" of source Documents, whether that is a text chunk, an image, or more. They also contain metadata and relationship information with other nodes and index structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f61de0-b210-4fc8-aaf9-a8ba55910257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "parser = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "nodes = parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06501aeb-ecc5-4236-8d7c-2228b1ad19be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nodes: 18\n",
      "Node ID: 856378fb-778e-41f8-8a48-47684b3734be, What I Worked On\n",
      "\n",
      "February 2021\n",
      "\n",
      "Before college th\n",
      "Node ID: 145e55c0-8029-42c8-9848-26f44cad73fc, It seemed only a matter of time before we'd have M\n",
      "Node ID: 4a851ab0-7b85-4d5d-8131-6c260f2dd1fe, There were some surplus Xerox Dandelions floating \n",
      "Node ID: 81ae6a47-ead3-436b-b5a1-085181b72f44, This was now only weeks away. My nice landlady let\n",
      "Node ID: 1d671e3b-6f6c-4d05-99dd-3ff60e2313e7, Our teacher, professor Ulivi, was a nice guy. He c\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Nodes: {len(nodes)}\")\n",
    "for node in nodes[:5]:\n",
    "    print(f\"Node ID: {node.node_id}, {node.text[0:50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b504f-2131-40b8-93c3-6379a5a205dd",
   "metadata": {},
   "source": [
    "### HierarchicalNodeParser && AutoMergingRetriever\n",
    "AutoMergingRetriever, which looks at a set of leaf nodes and recursively \"merges\" subsets of leaf nodes that reference a parent node beyond a given threshold. This allows us to consolidate potentially disparate, smaller contexts into a larger context that might help synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67753e88-941f-48de-8e57-6f790679e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b3217b2-f576-483f-ab34-334eedaa238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n",
      "\n",
      "The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing\n"
     ]
    }
   ],
   "source": [
    "doc_text = \"\\n\\n\".join([d.get_content() for d in documents])\n",
    "docs = [Document(text=doc_text)]\n",
    "\n",
    "print(len(docs),docs[0].text[100:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f71c5a3-15b1-464e-9ace-669c3662bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "node_parser = HierarchicalNodeParser.from_defaults()\n",
    "nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d67c732-35dd-40c3-be86-4e553c64e1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes\n",
    "\n",
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "len(leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96b18313-d1f5-4ae9-9ee9-512a16bae66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_nodes = get_root_nodes(nodes)\n",
    "len(root_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d7c510a-d78b-4f10-8c16-6351df13e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "\n",
    "# insert nodes into docstore\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "# define storage context (will include vector store by default too)\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "950c5a8e-adc8-412b-b14a-a8b388cd465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load index into vector index\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "base_index = VectorStoreIndex(\n",
    "    leaf_nodes,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43f1e084-bc87-42c3-81fa-7a6c2d497952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=6)\n",
    "retriever = AutoMergingRetriever(base_retriever, storage_context, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bf639f7-4fdb-4563-9a93-80bde63799e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = (\n",
    "    \"Who is Paul Graha?\"\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(query_str)\n",
    "base_nodes = base_retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "772490df-1ea3-465b-89fb-87c12ffed8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f352031-0a4c-453f-a264-b503ac15cfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45e8cadd-7b42-4df1-96ac-2ff40aed5426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** ccd2fd92-6b24-4a3b-8058-abdfef977896<br>**Similarity:** 0.1910078956684135<br>**Text:** The following spring, lightning struck. I was invited to give a talk at a Lisp conference, so I gave one about how we'd used Lisp at Viaweb. Afterward I put a postscript file of this talk online, on paulgraham.com, which I'd created years before using Viaweb but had never used for anything. In one day it got 30,000 page views. What on earth had happened? The referring urls showed that someone had posted it on Slashdot. [10]\n",
       "\n",
       "Wow, I thought, there's an audience.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** ea41480e-5b76-4bf1-9086-623873c35cf6<br>**Similarity:** 0.18024639939898324<br>**Text:** They were an impressive group. That first batch included reddit, Justin Kan and Emmett Shear, who went on to found Twitch, Aaron Swartz, who had already helped write the RSS spec and would a few years later become a martyr for open access, and Sam Altman, who would later become the second president of YC. I don't think it was entirely luck that the first batch was so good. You had to be pretty bold to sign up for a weird thing like the Summer Founders Program instead of a summer job at a legit place like Microsoft or Goldman Sachs.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** ed821ea3-e039-44e9-917e-3a7a4b6524fa<br>**Similarity:** 0.17983075248980943<br>**Text:** But I told few people about Bel while I was working on it. So for years it must have seemed that I was doing nothing, when in fact I was working harder than I'd ever worked on anything. Occasionally after wrestling for hours with some gruesome bug I'd check Twitter or HN and see someone asking \"Does Paul Graham still code?\"\n",
       "\n",
       "Working on Bel was hard but satisfying.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 78c4e181-adc2-4433-8655-b7b5ac0a73b7<br>**Similarity:** 0.17158860607657678<br>**Text:** That fall I started taking art classes at Harvard. Grad students could take classes in any department, and my advisor, Tom Cheatham, was very easy going. If he even knew about the strange classes I was taking, he never said anything.\n",
       "\n",
       "So now I was in a PhD program in computer science, yet planning to be an artist, yet also genuinely in love with Lisp hacking and working away at On Lisp. In other words, like many a grad student, I was working energetically on multiple projects that were not my thesis.\n",
       "\n",
       "I didn't see a way out of this situation.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 0a8a79ec-2d97-4a0c-bee0-7ed550b40b2d<br>**Similarity:** 0.171288554992616<br>**Text:** Three separate hosts would all invite their friends to one party. So for every guest, two thirds of the other guests would be people they didn't know but would probably like. One of the guests was someone I didn't know but would turn out to like a lot: a woman called Jessica Livingston. A couple days later I asked her out.\n",
       "\n",
       "Jessica was in charge of marketing at a Boston investment bank. This bank thought it understood startups, but over the next year, as she met friends of mine from the startup world, she was surprised how different reality was. And how colorful their stories were.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** eb745a47-c9aa-4e5c-804d-f510924d4549<br>**Similarity:** 0.1663666158376561<br>**Text:** I also worked on spam filters, and did some more painting. I used to have dinners for a group of friends every thursday night, which taught me how to cook for groups. And I bought another building in Cambridge, a former candy factory (and later, twas said, porn studio), to use as an office.\n",
       "\n",
       "One night in October 2003 there was a big party at my house. It was a clever idea of my friend Maria Daniels, who was one of the thursday diners. Three separate hosts would all invite their friends to one party.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6723ee0-1e2c-4992-ba2e-201b5033543f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** ccd2fd92-6b24-4a3b-8058-abdfef977896<br>**Similarity:** 0.1910078956684135<br>**Text:** The following spring, lightning struck. I was invited to give a talk at a Lisp conference, so I gave one about how we'd used Lisp at Viaweb. Afterward I put a postscript file of this talk online, on paulgraham.com, which I'd created years before using Viaweb but had never used for anything. In one day it got 30,000 page views. What on earth had happened? The referring urls showed that someone had posted it on Slashdot. [10]\n",
       "\n",
       "Wow, I thought, there's an audience.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** ea41480e-5b76-4bf1-9086-623873c35cf6<br>**Similarity:** 0.18024639939898324<br>**Text:** They were an impressive group. That first batch included reddit, Justin Kan and Emmett Shear, who went on to found Twitch, Aaron Swartz, who had already helped write the RSS spec and would a few years later become a martyr for open access, and Sam Altman, who would later become the second president of YC. I don't think it was entirely luck that the first batch was so good. You had to be pretty bold to sign up for a weird thing like the Summer Founders Program instead of a summer job at a legit place like Microsoft or Goldman Sachs.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** ed821ea3-e039-44e9-917e-3a7a4b6524fa<br>**Similarity:** 0.17983075248980943<br>**Text:** But I told few people about Bel while I was working on it. So for years it must have seemed that I was doing nothing, when in fact I was working harder than I'd ever worked on anything. Occasionally after wrestling for hours with some gruesome bug I'd check Twitter or HN and see someone asking \"Does Paul Graham still code?\"\n",
       "\n",
       "Working on Bel was hard but satisfying.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 78c4e181-adc2-4433-8655-b7b5ac0a73b7<br>**Similarity:** 0.17158860607657678<br>**Text:** That fall I started taking art classes at Harvard. Grad students could take classes in any department, and my advisor, Tom Cheatham, was very easy going. If he even knew about the strange classes I was taking, he never said anything.\n",
       "\n",
       "So now I was in a PhD program in computer science, yet planning to be an artist, yet also genuinely in love with Lisp hacking and working away at On Lisp. In other words, like many a grad student, I was working energetically on multiple projects that were not my thesis.\n",
       "\n",
       "I didn't see a way out of this situation.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 0a8a79ec-2d97-4a0c-bee0-7ed550b40b2d<br>**Similarity:** 0.171288554992616<br>**Text:** Three separate hosts would all invite their friends to one party. So for every guest, two thirds of the other guests would be people they didn't know but would probably like. One of the guests was someone I didn't know but would turn out to like a lot: a woman called Jessica Livingston. A couple days later I asked her out.\n",
       "\n",
       "Jessica was in charge of marketing at a Boston investment bank. This bank thought it understood startups, but over the next year, as she met friends of mine from the startup world, she was surprised how different reality was. And how colorful their stories were.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** eb745a47-c9aa-4e5c-804d-f510924d4549<br>**Similarity:** 0.1663666158376561<br>**Text:** I also worked on spam filters, and did some more painting. I used to have dinners for a group of friends every thursday night, which taught me how to cook for groups. And I bought another building in Cambridge, a former candy factory (and later, twas said, porn studio), to use as an office.\n",
       "\n",
       "One night in October 2003 there was a big party at my house. It was a clever idea of my friend Maria Daniels, who was one of the thursday diners. Three separate hosts would all invite their friends to one party.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for node in base_nodes:\n",
    "    display_source_node(node, source_length=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cff90ee5-dbee-4d88-aaca-9a18f7c399eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dda50cf-5dd9-4e06-b122-d6b7cd0ad885",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "base_query_engine = RetrieverQueryEngine.from_args(base_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a3e0296-dbb1-4b57-b0fb-e0595c4bf299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a computer scientist, entrepreneur, and writer known for his work with Lisp programming and for founding Viaweb, one of the first web-based applications. He has been involved in various projects, including the Summer Founders Program and has contributed to the startup community. Additionally, he has written extensively about technology and entrepreneurship.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(query_str)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e53568c1-dd2b-4f86-99dd-a83b1b6c1db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a computer scientist and entrepreneur known for his work with Lisp programming and for co-founding the startup incubator Y Combinator (YC). He has a background in both computer science and art, and he has been involved in various projects, including the development of spam filters and the writing of the book \"On Lisp.\" Additionally, he has had a significant impact on the startup community, connecting with influential figures in the tech industry.\n"
     ]
    }
   ],
   "source": [
    "base_response = base_query_engine.query(query_str)\n",
    "print(base_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaIndex",
   "language": "python",
   "name": "llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
