{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1472cb-ab1f-48fc-b8d2-e369baee4557",
   "metadata": {},
   "source": [
    "## Setting LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d45b36d-757f-4acd-8083-995138095f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b5c8e0-4619-40e1-9141-f3196290ff92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "#print(\"Open AI - \",os.getenv(\"LITELLM_URL\"),os.getenv(\"OPENAI_API_MODEL\"), os.getenv(\"OPENAI_API_EMBEDDING\"))\n",
    "#print(\"OLLAMA  - \",os.getenv(\"OLLAMA_URL\"),os.getenv(\"OLLAMA_MODEL\"))\n",
    "#print(\"Local OLLAMA - \",os.getenv(\"OLLAMA_LOCAL_URL\"),os.getenv(\"OLLAMA_LOCAL_MODEL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c5c71d-7466-40e9-a6d9-e62837f621ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8a433aa-4f89-4e06-8acd-780e730536bd",
   "metadata": {},
   "source": [
    "### RUN LLM AS OLLAMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4008df15-e79d-4fb2-8269-08182ae74b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install OPEN AI LLM, skip if already installed\n",
    "!pipenv install llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88433662-bed6-4bdf-8991-f02f730792b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "The capital of France is **Paris**. ðŸ‡«ðŸ‡·  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "api_base=os.getenv(\"OLLAMA_LOCAL_URL\")\n",
    "model=os.getenv(\"OLLAMA_LOCAL_MODEL\")\n",
    "Settings.llm = Ollama(model=model, base_url=api_base,request_timeout=360.0)\n",
    "\n",
    "# use remote ollam\n",
    "\"\"\"\n",
    "api_base=os.getenv(\"OLLAMA_URL\")\n",
    "model=os.getenv(\"OLLAMA_MODEL\")\n",
    "llm = Ollama(model=model, base_url=api_base,request_timeout=360.0)\n",
    "\"\"\"\n",
    "#test run\n",
    "response = Settings.llm.complete(\"What is the capital of France?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34bf597-435b-464d-afc4-49f852d60479",
   "metadata": {},
   "source": [
    "### RUN LLM AS OPEN AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10f8e1-1bef-44e4-bb0d-671a5a7ac66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install OPEN AI LLM, skip if already installed\n",
    "!pipenv install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cca4af2b-3cbf-42b5-8a0c-eccb3e796188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "api_base=os.getenv(\"LITELLM_URL\")\n",
    "model=os.getenv(\"OPENAI_API_MODEL\")\n",
    "\n",
    "Settings.llm = OpenAI(\n",
    "    model=model,\n",
    "    api_base = api_base,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# resp = Settings.llm.complete(\"What is the capital of France?\")\n",
    "# print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f57c66-5521-4e24-9197-07ce916f7491",
   "metadata": {},
   "source": [
    "## Setting Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f1d1b49-087e-49e3-906b-da53d09fd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use open AI embedding\n",
    "# can skip if use local embedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "api_base=os.getenv(\"LITELLM_URL\")\n",
    "embedding_model=os.getenv(\"OPENAI_API_EMBEDDING\")\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model_name=embedding_model,\n",
    "    api_base = api_base,\n",
    ")\n",
    "# embed_text = Settings.embed_model.get_text_embedding(\"hello\")\n",
    "# print(f\"{len(embed_text)}, {embed_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e1a5b2d-b956-4d98-abf3-be4d88bce361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f809f11-dec8-4a34-8ca5-e18777f56a50",
   "metadata": {},
   "source": [
    "### Load and Parse document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e0ceced-ddc8-4648-be44-c594967664e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleKeywordTableIndex\n",
    "from llama_index.core import SummaryIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed08805f-6e69-4952-b701-59cdf35ddf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader,Document\n",
    "documents = SimpleDirectoryReader(\"./data/paul\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f6d1c6c-c325-4f98-b248-f71bce440da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "nodes = SentenceSplitter().get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081098b-7064-4240-a806-36fdd82d2b07",
   "metadata": {},
   "source": [
    "## Chat Store using simple chat store in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b544bb8b-66b0-4a7e-b827-7933cf0f9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.chat_store import SimpleChatStore\n",
    "from llama_index.core.memory import ChatMemoryBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07732e0f-842f-4335-b8ed-b59d67d0d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_store = SimpleChatStore()\n",
    "\n",
    "chat_memory = ChatMemoryBuffer.from_defaults(\n",
    "    token_limit=3000,\n",
    "    chat_store=chat_store,\n",
    "    chat_store_key=\"user1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d83a68e1-1496-4af4-a30d-4f98b96d24f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9202497e-004b-4724-8fdc-d14b3c9ca17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = index.as_chat_engine(memory=chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f51ca0b-7fb9-43f6-bf24-5031335da6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing up, the author focused on writing and programming outside of school. They initially wrote short stories, which they later described as lacking plot but featuring characters with strong feelings. In 9th grade, they began programming on an IBM 1401, using punch cards to input their programs. Later, they acquired a TRS-80 microcomputer, which allowed them to write simple games, a program for predicting model rocket flights, and a word processor for their father. Although they enjoyed programming, the author initially planned to study philosophy in college but eventually switched to studying artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03ce247f-4c6b-4e11-af65-2fabd128241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_store.persist(persist_path=\"chat_store.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0b6ad84-1826-4a58-b08c-bf50fabe961e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ChatMemoryBuffer.to_dict of ChatMemoryBuffer(chat_store=SimpleChatStore(store={'user1': [ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='What did the author do growing up?')]), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': [ChatCompletionMessageToolCall(id='call_IqblU3B3aMuSCrByBTny7wmf', function=Function(arguments='{\"input\":\"What did the author do growing up?\"}', name='query_engine_tool'), type='function')]}, blocks=[]), ChatMessage(role=<MessageRole.TOOL: 'tool'>, additional_kwargs={'name': 'query_engine_tool', 'tool_call_id': 'call_IqblU3B3aMuSCrByBTny7wmf'}, blocks=[TextBlock(block_type='text', text='Growing up, the author focused on writing and programming outside of school. Initially, they wrote short stories, which they later described as lacking plot but featuring characters with strong feelings. They began programming on an IBM 1401 in 9th grade, using punch cards to input their programs. Later, they acquired a TRS-80 microcomputer, which allowed them to write simple games, a program for predicting model rocket flights, and a word processor for their father. Despite enjoying programming, the author initially planned to study philosophy in college but eventually switched to studying artificial intelligence.')]), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Growing up, the author focused on writing and programming outside of school. They initially wrote short stories, which they later described as lacking plot but featuring characters with strong feelings. In 9th grade, they began programming on an IBM 1401, using punch cards to input their programs. Later, they acquired a TRS-80 microcomputer, which allowed them to write simple games, a program for predicting model rocket flights, and a word processor for their father. Although they enjoyed programming, the author initially planned to study philosophy in college but eventually switched to studying artificial intelligence.')])]}), chat_store_key='user1', token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'))>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bdadb5b-2410-45fd-af56-96c3b3cbacf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After his time at Y Combinator, the author decided to step back and hand over the leadership to someone else, specifically seeking to recruit Sam Altman as the new president. He initially intended to balance writing essays, working on Y Combinator, and developing the programming language Arc. However, as Y Combinator grew, it consumed more of his attention. Ultimately, he focused on writing essays and pursuing other projects.\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.query(\"What did the author do after his time at YC?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8b2ee2c-d938-45a1-b450-b788cc4702ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ChatMemoryBuffer.to_dict of ChatMemoryBuffer(chat_store=SimpleChatStore(store={'user1': [ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='What did the author do after his time at YC?')]), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': [ChatCompletionMessageToolCall(id='call_vra67bjSt6pjeMg8P3wWv5SY', function=Function(arguments='{\"input\":\"What did the author do after his time at Y Combinator (YC)?\"}', name='query_engine_tool'), type='function')]}, blocks=[]), ChatMessage(role=<MessageRole.TOOL: 'tool'>, additional_kwargs={'name': 'query_engine_tool', 'tool_call_id': 'call_vra67bjSt6pjeMg8P3wWv5SY'}, blocks=[TextBlock(block_type='text', text='The author did not initially intend for Y Combinator (YC) to become a full-time job, as he planned to focus on hacking, writing essays, and working on YC. However, as YC grew and he became more excited about it, it started to occupy a significant portion of his attention. In the summer of 2006, he began working on a new version of Arc, which was faster because it was compiled into Scheme. To test this new version, he created Hacker News, originally intended as a news aggregator for startup founders but later rebranded to focus on engaging intellectual curiosity. While Hacker News benefited YC, it also became a significant source of stress for him.')]), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='After his time at Y Combinator (YC), the author initially did not intend for YC to become a full-time commitment, as he wanted to focus on hacking, writing essays, and working on YC itself. However, as YC grew and he became more excited about it, it started to take up a significant amount of his attention. In the summer of 2006, he began working on a new version of Arc, which was faster because it was compiled into Scheme. To test this new version, he created Hacker News, which was originally intended as a news aggregator for startup founders but later evolved to focus on engaging intellectual curiosity. While Hacker News benefited YC, it also became a significant source of stress for him.')])]}), chat_store_key='user1', token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'))>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.to_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-2",
   "language": "python",
   "name": "llama-index-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
